#############################
# YASS configuration schema #
#############################

data:
  type: dict
  schema:
    # project's root folder, data will be loaded and saved here
    # can be an absolute or relative path
    root_folder:
      type: string
      required: True
    # recordings filename, relative to root folder
    recordings:
      type: string
      required: True
    # channel geometry filename, relative to root folder
    geometry:
      type: string
      required: True

resources:
  type: dict
  schema:
    # maximum memory allowed in batch processing, can be a number (bytes)
    # or a string such as 1000MB, 2GB
    max_memory:
      required: True


recordings:
  type: dict
  schema:
    # precision of the recording â€“ must be a valid numpy dtype
    dtype:
      type: string
      required: True
    # recording rate (in Hz)
    sampling_rate:
      type: int
      required: True
    # number of channels
    n_channels: 10
      type: int
      required: True
    # channels spatial radius
    spatial_radius:
      type: int
      required: True
    # temporal length of wavforms in ms
    spike_size_ms:
      type: float
      required: True
    # recordings format: wide (number of channel x number of observations)
    # or long (number of oservations x number of channels)
    format: long
      type: string
      required: True

preprocess:
  type: dict
  schema:
    # apply butterworth filter in the preprocessing step?
    filter:
      type: bool
      required: False
      default: True
    # output dtype for transformed data
    dtype:
      type: string
      default: float64

spikes:
  type: dict
  schema:
    # 'nn' for neural net detction, 'threshold' for amplitude threshold detection
    detection:
      type: string
      required: True
      allowed: [threshold, nn]
    # number of features in the temporal dimension to use when applying
    # dimensionality reduction
    temporal_features:
      type: int
      default: 3

deconvolution:
  type: dict
  schema:
    # refractory period violation in time bins
    n_rf:
      type: float
      default: 1.5
    # threshold on template scale
    threshold_a:
      type: float
      default: 0.3
    # threshold on decrease in L2 difference
    threshold_dd:
      type: float
      default: 0
    # size of windows to look consider around spike time for deconv. 
    n_explore:
      type: int
      default: 2
    # upsampling factor of templates
    unsample_factor:
      type: int
      default: 5


neural_network_detector:
  type: dict
  schema:
    # model name, can be any of the models included in yass (detectnet1.ckpt),
    # a relative folder to data.root_fodler (e.g.
    # $ROOT_FOLDER/models/mymodel.ckpt) or an absolute path to a model
    # (e.g. /path/to/my/model.ckpt). In the same folder as your model, there
    # must be a yaml file with the number and size of the filters, the file
    # should be named exactly as your model but with yaml extension
    # see yass/src/assets/models/ for an example
    filename:
      type: string
      default: detect_nn1.ckpt
    # Threshold for spike event detection
    threshold_spike:
      type: float
      default: 0.5


neural_network_triage:
  type: dict
  schema:
    # same rules apply as in neural_network_detector.filename but the
    # yaml file should only contain size (not number)
    filename:
      type: string
      default: triage_nn1.ckpt
    # Threshold for spike event detection
    threshold_collision:
      type: float
      default: 0.5


neural_network_autoencoder:
  type: dict
  schema:
    filename:
      # same rules apply as in neural_network_detector.filename but no
      # yaml file is needed
      type: string
      default: ae_nn1.ckpt



cluster_prior:
  type: dict
  schema:
    beta:
      type: int
      default: 1
    a:
      type: int
      default: 1
    lambda0:
      type: float
      default: 0.01
    mu:
      type: list
      default: [[0], [0], [0]]
    nu:
      type: int
      default: 5
    V:
      type: int
      default: 2

filter:
  type: dict
  schema:
    # Order of Butterworth filter
    order:
      type: int
      default: 3
    # Low pass frequency (Hz)
    low_pass_freq:
      type: int
      default: 300
    # High pass factor (proportion of sampling rate)
    high_factor:
      type: float
      default: 0.1

triage:
  type: dict
  schema:
    # number of nearest neighbors to consider
    nearest_neighbors:
      type: int
      default: 20
    # percentage of data to be triaged
    percent:
      type: float
      default: 0.1

coreset:
  type: dict
  schema:
    # Num. of clusters
    clusters:
      type: int
      default: 10
    # distance threshold
    threshold:
      type: float
      int: 0.95

clustering:
  type: dict
  schema:
    # Masking threshold
    masking_threshold:
      type: list
      default: [0.9, 0.5]
    # Num. of new clusters in split
    n_split:
      type: int
      default: 5
    # Choose 'location' for location (x and y : 2 features) + main channel 
    # features (n_feature dimensional) as the feature space. Calculates the location 
    # of the events using a weighted average of the power in the main_channel 
    # and neighboring channels.
    # Choose 'neigh_chan' for n_feature x neighboring_channels dimensional feature 
    # space. The feature space is defined by feature summarization of the waveforms 
    # into n_feature dimensional feature space for only the main_channel and the 
    # neighboring channels (This key (clustering.clustering_method) is not optional)
    clustering_method:
      type: string
      default: 'location'
    # maximum number of spikes per clustering group
    # if the total number of spikes per clustering group exceeds it,
    # it randomly subsample
    max_n_spikes:
        type: int
        default: 10000

templates:
  type: dict
  schema:
    merge_threshold:
      type: list
      default: [0.8, 0.7]
