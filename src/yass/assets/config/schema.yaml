#############################
# YASS configuration schema #
#############################

# Definition reference: http://docs.python-cerberus.org/en/stable/

data:
  type: dict
  required: True
  schema:
    # project's root folder, data will be loaded and saved here
    # can be an absolute or relative path
    root_folder:
      type: string
      required: True
    # recordings filename, relative to root folder
    recordings:
      type: string
      required: True
    # channel geometry filename, relative to root folder
    geometry:
      type: string
      required: True
    stimulus:
      type: string
      required: False
      default: None
    triggers:
      type: string
      required: False
      default: None

resources:
  type: dict
  required: True
  schema:
    multi_processing: 
      type: [integer, string]
      required: True
      default: 0
    n_processors: 
      type: [integer, string]
      required: True
      default: 1
    n_sec_chunk: 
      type: [integer, string]
      required: True
      default: 2
    n_sec_chunk_gpu_detect:
      type: [integer, string]
      required: True
      default: 1
    n_sec_chunk_gpu_deconv:
      type: [integer, string]
      required: True
      default: 1
    n_gpu_processors:
      type: integer
      default: 1

recordings:
  type: dict
  required: True
  schema:
    # precision of the recording â€“ must be a valid numpy dtype
    dtype:
      type: string
      required: True
    # recording rate (in Hz)
    sampling_rate:
      type: integer
      required: True
    # number of channels
    n_channels:
      type: integer
      required: True
    # channels spatial radius
    spatial_radius:
      type: integer
      required: True
    # temporal length of wavforms in ms
    spike_size_ms:
      type: float
      required: True
    # chunk for clustering
    clustering_chunk:
      default:
    # chunk for final deconv
    final_deconv_chunk:
      default:

preprocess:
  type: dict
  default:
    apply_filter: True
    dtype: float64
    filter:
      order: 3
      low_pass_freq: 300
      high_factor: 0.45
  schema:
    # apply butterworth filter in the preprocessing step?
    apply_filter:
      type: boolean
      default: True
    # output dtype for transformed data
    dtype:
      type: string
      default: float64
    filter:
      type: dict
      default:
        order: 3
        low_pass_freq: 300
        high_factor: 0.45
      schema:
        # Order of Butterworth filter
        order:
          type: integer
          default: 3
        # Low pass frequency (Hz)
        low_pass_freq:
          type: integer
          default: 300
        # High pass factor (proportion of sampling rate)
        high_factor:
          type: float
          default: 0.45

detect:
  type: dict
  default:
    threshold: 0.5
  schema:
    threshold:
      type: float
      default: 0.5

cluster:
  type: dict
  default:
    max_n_spikes: 10000
    knn_triage: 0.01
    min_fr: 0.1
    prior:
      beta: 1
      a: 1
      lambda0: 0.01
      nu: 5
      V: 2
    max_mad_violation: 10
  schema:
    max_n_spikes:
      type: integer
      default: 10000
    knn_triage:
      type: float
      default: 0.01
    prior:
      type: dict
      default:
        beta: 1
        a: 1
        lambda0: 0.01
        nu: 5
        V: 2
      schema:
        beta:
          type: integer
          default: 1
        a:
          type: integer
          default: 1
        lambda0:
          type: float
          default: 0.01
        nu:
          type: integer
          default: 5
        V:
          type: integer
          default: 2

deconvolution:
  type: dict
  default:
    threshold: 20
    deconv_gpu: True
  schema:
    threshold:
      type: float
      default: 20
    deconv_gpu:
      type: boolean
      default: True

neuralnetwork:
  type: dict
  default:
    apply_nn: True
    detect:
      filename: detect.pt  
      n_filters: [16, 8, 8] 
    denoise:
      filename: denoise.pt
      n_filters: [16, 8, 4]
      filter_sizes : [5, 11, 21]
    training:
      input_spike_train_filname:
      spike_size_ms:
  schema:
    training:
      type: dict
      default:
        input_spike_train_filname:
        spike_size_ms:

clean_up:
  type: dict
  default:
    abs_max_diff: 1.2
    rel_max_diff: 0.15
    min_ptp: 3
    off_center: 5
    mad:
      min_var_gap: 2
      max_violations: 10
